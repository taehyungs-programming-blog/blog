---
layout: default
title: "11. mimalloc"
parent: "(OpenSource 👨‍💻)"
grand_parent: (C++)
nav_order: 2
---

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## mimalloc이란?

* mimalloc은 Microsoft Research에서 개발한 고성능 메모리 할당자
    * [Github](https://github.com/microsoft/mimalloc)

---

## 사전 정의

* 3단계 계층 구조:
    * Heap (힙): 스레드별 로컬 힙
    * Segment (세그먼트): 32GB 크기의 큰 메모리 청크
    * Page (페이지): 64KB/512KB 크기의 실제 할당 단위

* 크기별 전략:
    * Small (≤8KB): 64KB 페이지에서 할당
    * Medium (≤64KB): 512KB 페이지에서 할당
    * Large (≤16MB): 전용 세그먼트에서 할당
    * Huge (>16MB): 가변 크기 세그먼트

---

## Example

```cpp
#include <stdio.h>
#include <string.h>
#include "mimalloc.h"

void basic_usage_example() {
    printf("=== 기본 사용법 ===\n");
    
    // 1. 기본 할당/해제 - malloc/free와 동일한 인터페이스
    void* ptr1 = mi_malloc(1024);
    printf("할당된 주소: %p\n", ptr1);
    mi_free(ptr1);
    
    // 2. 0으로 초기화된 메모리 할당
    void* ptr2 = mi_zalloc(512);
    printf("0 초기화 메모리: %p\n", ptr2);
    mi_free(ptr2);
    
    // 3. 배열 할당 (calloc과 유사)
    int* arr = (int*)mi_calloc(100, sizeof(int));
    printf("배열 할당: %p\n", arr);
    mi_free(arr);
    
    // 4. 정렬된 메모리 할당
    void* aligned_ptr = mi_malloc_aligned(1024, 64); // 64바이트 정렬
    printf("64바이트 정렬 메모리: %p\n", aligned_ptr);
    mi_free(aligned_ptr);
}

void heap_usage_example() {
    printf("\n=== 힙 사용법 ===\n");
    
    // 1. 전용 힙 생성 - 스레드별 독립적인 힙
    mi_heap_t* heap = mi_heap_new();
    printf("새 힙 생성: %p\n", heap);
    
    // 2. 특정 힙에서 할당
    void* ptr1 = mi_heap_malloc(heap, 256);
    void* ptr2 = mi_heap_malloc(heap, 512);
    printf("힙에서 할당: %p, %p\n", ptr1, ptr2);
    
    // 3. 힙 전체 해제 - 모든 블록이 한번에 해제됨
    mi_heap_destroy(heap);
    printf("힙 전체 해제 완료\n");
}

void performance_features() {
    printf("\n=== 성능 기능들 ===\n");
    
    // 1. 작은 객체 빠른 할당
    void* small_ptr = mi_malloc_small(64); // 작은 객체 최적화 경로
    printf("작은 객체 할당: %p\n", small_ptr);
    mi_free(small_ptr);
    
    // 2. 통계 정보 출력
    mi_stats_print_out(NULL, NULL);
    
    // 3. 가비지 컬렉션 (사용하지 않는 페이지 정리)
    mi_collect(false); // 강제로 수집하지 않음
    printf("메모리 정리 완료\n");
}

int main() {
    // mimalloc 초기화 (보통 자동으로 됨)
    mi_process_init();
    
    basic_usage_example();
    heap_usage_example();
    performance_features();
    
    printf("\nmimalloc 버전: %d\n", mi_version());
    
    // 정리 (보통 자동으로 됨)
    mi_process_done();
    return 0;
}
```

---

## mimalloc은 어떤식으로 최적화를 했을까?

### 1. 초고속 할당 경로 (Fast Path) 구현

* 핵심 알고리즘 (src/alloc.c:30-50)

```c
extern inline void* _mi_page_malloc_zero(mi_heap_t* heap, mi_page_t* page, size_t size, bool zero) {
  // 1. Free list 체크 (단일 NULL 테스트)
  mi_block_t* const block = page->free;
  if mi_unlikely(block == NULL) {
    return _mi_malloc_generic(heap, size, zero, 0);  // 느린 경로로 이동
  }
  
  // 2. 다음 블록 포인터 가져오기 (단일 메모리 읽기)
  page->free = mi_block_next(page, block);
  
  // 3. 사용 카운터 증가 (단일 증가 연산)
  page->used++;
  
  // 이게 전부! 릴리즈 모드에서 단 7개 어셈블리 명령어
  return block;
}
```

* 사전지식:
    * Free list는 사용 가능한(해제된) 메모리 블록들을 연결한 링크드 리스트

```cpp
// 해제된 메모리 블록의 구조
typedef struct mi_block_s {
  mi_encoded_t next;  // 다음 해제된 블록을 가리키는 포인터
} mi_block_t;
```

```
페이지 메모리 레이아웃:
┌─────────┬─────────┬─────────┬─────────┐
│ Block A │ Block B │ Block C │ Block D │
│ (사용중) │ (FREE) │ (FREE) │ (사용중) │
└─────────┴─────────┴─────────┴─────────┘

Free List 연결:
page->free → Block B → Block C → NULL
             ↑next      ↑next
```

* 성능 최적화 포인트:

- **분기 예측**: `mi_unlikely()` 매크로로 컴파일러에게 힌트 제공
- **인라인**: `extern inline`으로 함수 호출 오버헤드 제거  
- **단일 테스트**: NULL 체크 하나로 빠른/느린 경로 결정
- **캐시 효율성**: 페이지 내에서 순차적 접근 패턴

---

### 2. 스레드 로컬 힙 최적화

* (사전지식) 스레드 로컬 힙이 필요한 이유?

```
// 전통적인 문제 상황
Thread A: ptr = malloc(1024);        // A 힙에서 할당
Thread B: free(ptr);                 // 어떻게 해제하지? A 힙? B 힙?

// 만약 각자 힙을 쓴다면...
Thread A의 힙: [1024바이트가 사용중인 상태]
Thread B의 힙: [이 메모리에 대해 전혀 모름]
→ 메모리 누수 발생!
```

```
// 전통적인 malloc - 모든 스레드가 하나의 힙 공유
Thread 1: malloc(100) → 🔒 LOCK → 할당 → 🔓 UNLOCK
Thread 2: malloc(200) → ⏰ 대기... → 🔒 LOCK → 할당 → 🔓 UNLOCK
Thread 3: malloc(50)  → ⏰ 대기... → ⏰ 대기... → 🔒 LOCK → 할당
```

```
// 각 스레드마다 독립적인 힙
Thread 1: mi_malloc(100) → Heap A → 즉시 할당 ✅
Thread 2: mi_malloc(200) → Heap B → 즉시 할당 ✅
Thread 3: mi_malloc(50)  → Heap C → 즉시 할당 ✅
```

* Lock-Free 멀티스레딩:
    * 각 스레드가 독립적인 힙을 가짐
    * 작은 객체 할당/해제는 완전히 lock-free
    * 크로스 스레드 해제만 원자적 연산 사용

----

### 3. 캐시 친화적 데이터 구조

* (사전지식) cpu 속도의 차이
    * CPU는 메모리를 64바이트 단위(캐시 라인)로 가져옵니다. 즉, 1바이트를 읽어도 64바이트를 통째로 가져와야 한다

```c

typedef struct mi_page_s {
  // === 첫 번째 캐시 라인 (0-63바이트) ===
  // 🚀 할당/해제 시 가장 자주 접근하는 필드들
  uint32_t slice_count;        //  0-3바이트   
  uint32_t slice_offset;       //  4-7바이트
  uint8_t  is_committed:1;     //  8바이트 (비트필드)
  uint8_t  is_zero_init:1;     //  8바이트 
  uint8_t  is_huge:1;          //  8바이트
  
  uint16_t capacity;           //  9-10바이트  ⭐ 가장 중요!
  uint16_t reserved;           // 11-12바이트  ⭐ 중요!
  mi_page_flags_t flags;       // 13바이트     ⭐ 중요!
  uint8_t  free_is_zero:1;     // 14바이트    
  uint8_t  retire_expire:7;    // 14바이트
  
  mi_block_t* free;            // 16-23바이트  ⭐ 가장 중요!
  mi_block_t* local_free;      // 24-31바이트  ⭐ 중요!
  uint16_t used;               // 32-33바이트  ⭐ 중요!
  uint8_t  block_size_shift;   // 34바이트
  uint8_t  heap_tag;           // 35바이트
  
  size_t   block_size;         // 36-43바이트  ⭐ 중요!
  uint8_t* page_start;         // 44-51바이트  ⭐ 중요!
  uintptr_t keys[2];           // 52-67바이트
  
  // === 두 번째 캐시 라인 (64-127바이트) ===  
  // 🐌 덜 자주 접근하는 필드들
  _Atomic(mi_thread_free_t) xthread_free;  // 68-75바이트 (가끔 접근)
  _Atomic(uintptr_t) xheap;               // 76-83바이트 (가끔 접근)
  // ... 기타 필드들
};
```

* 데이터 구조 (include/mimalloc/types.h:285-330)

---

### 4. 멀티스레드 해제 최적화 (Delayed Free)

* 기존 free의 문제

```cpp
// Thread A에서 할당
Thread A: char* ptr = malloc(1024);

// Thread B에서 해제 시도
Thread B: free(ptr);  // 어떻게 해제하지???

/*
ptr은 Thread A의 힙에서 할당됨
Thread B는 Thread A의 힙에 접근할 수 없음 (private)
글로벌 힙으로 보내면 → Lock 필요 → 성능 저하
*/
```

```cpp
void mi_free(void* p) {
  // 1. 포인터에서 세그먼트 정보 추출
  mi_segment_t* const segment = mi_checked_ptr_segment(p, "mi_free");
  
  // 2. 🔑 핵심: 소유권 확인!
  const bool is_local = (_mi_prim_thread_id() == mi_atomic_load_relaxed(&segment->thread_id));
  
  if (is_local) {
    // 내가 할당한 메모리 → 즉시 해제 (빠른 경로)
    mi_free_block_local(page, block, true, false);
  }
  else {
    // 🚨 다른 스레드가 할당한 메모리 → 특별 처리 필요!
    mi_free_generic_mt(page, segment, p);
  }
}
```

* 지연 해제는 어떤식?

```cpp
static void mi_free_block_delayed_mt(mi_page_t* page, mi_block_t* block) {
  // 1. 페이지의 크로스 스레드 해제 리스트에 추가 시도
  mi_thread_free_t tfree = mi_atomic_load_relaxed(&page->xthread_free);
  
  do {
    if (첫 번째_크로스_스레드_해제) {
      // 힙의 지연 해제 리스트로 보내기
      use_delayed = true;
    }
    else {
      // 페이지 로컬 리스트에 직접 추가
      mi_block_set_next(page, block, mi_tf_block(tfree));
      tfreex = mi_tf_set_block(tfree, block);
    }
  } while (!mi_atomic_cas_weak_release(&page->xthread_free, &tfree, tfreex));
}
```

### 최적화 효과:
- **캐시 지역성**: 소유 스레드가 나중에 일괄 처리
- **원자적 연산 최소화**: 대부분의 경우 단순 리스트 추가
- **메모리 순서**: Release/Acquire로 필요한 동기화만 수행

---

### 5. 원자적 비트맵 할당 (Arena Allocation)

* 원자적 비트맵 할당은 **대용량 메모리 블록(Arena)**을 멀티스레드 환경에서 안전하고 빠르게 할당하는 방법

```
Arena 구조:
┌─────────────────────────────────────────────────────────┐
│                   Arena (예: 4GB)                      │
├─────────┬─────────┬─────────┬─────────┬─────────┬──────┤
│ Block 0 │ Block 1 │ Block 2 │ Block 3 │ Block 4 │ ...  │
│ (64MB) │ (64MB) │ (64MB) │ (64MB) │ (64MB) │      │
├─────────┼─────────┼─────────┼─────────┼─────────┼──────┤
│  FREE   │  USED   │  FREE   │  FREE   │  USED   │ ...  │
└─────────┴─────────┴─────────┴─────────┴─────────┴──────┘
    0        1        2        3        4       ...
```

* 기존문제?

```
// 문제 상황: 여러 스레드가 동시에 Arena에서 할당 시도
Thread A: 300MB 할당 요청 → Block 2,3,4,5 필요 (4개 블록)
Thread B: 200MB 할당 요청 → Block 2,3,4 필요 (3개 블록)
Thread C: 100MB 할당 요청 → Block 3,4 필요 (2개 블록)

// 🚨 동시에 접근하면...
모든 스레드가 Block 2,3,4를 "사용 가능"하다고 판단!
→ 같은 메모리를 여러 스레드에게 할당
→ 메모리 충돌!
```

* 비트맵 = 각 블록의 사용 상태를 비트로 표현

```
// 64비트 시스템에서 MI_BITMAP_FIELD_BITS = 64
typedef _Atomic(size_t) mi_bitmap_field_t;  // 64비트 원자적 정수

// Arena의 블록 상태를 비트맵으로 표현:
// 0 = FREE, 1 = USED
비트맵 필드 0: 01001000... (Block 0,1,2,3... 64개 블록 상태)
비트맵 필드 1: 11000100... (Block 64,65,66... 다음 64개 블록 상태)
```

* 예시를 들어보자면 ...

```
// 300MB 할당 요청 → 5개 블록 필요 → 연속된 5개의 0비트 찾기
비트맵: 01001000111000... 
           ↑ 
        여기서 5개 연속 0비트 발견!
```

```cpp
const size_t mask = mi_bitmap_mask_(count, 0);
// count=5인 경우 mask = 00011111 (5개 비트)

size_t m = (mask << bitidx);
// bitidx=3인 경우 m = 01111100 (3번째부터 5개 비트)
```

```cpp
const size_t newmap = (map | m);
// 기존:    01001000111000...
// 마스크:  01111100000000...  
// 결과:    01111100111000... (5개 블록이 USED로 변경)

if (!mi_atomic_cas_strong_acq_rel(field, &map, newmap)) {
    // CAS 실패 → 다른 스레드가 먼저 할당함 → 다시 시도
    continue;
}
else {
    // CAS 성공 → 할당 완료!
    return true;
}
```

* 비트맵 기반 할당 (src/bitmap.c:40-100)

```c
inline bool _mi_bitmap_try_find_claim_field(mi_bitmap_t bitmap, size_t idx, 
                                            const size_t count, mi_bitmap_index_t* bitmap_idx) {
  mi_bitmap_field_t* field = &bitmap[idx];
  size_t map = mi_atomic_load_relaxed(field);
  
  if (map == MI_BITMAP_FIELD_FULL) return false;  // 빠른 실패
  
  const size_t mask = mi_bitmap_mask_(count, 0);
  const size_t bitidx_max = MI_BITMAP_FIELD_BITS - count;
  
#ifdef MI_HAVE_FAST_BITSCAN
  size_t bitidx = mi_ctz(~map);    // 하드웨어 지원 비트 스캔
#else
  size_t bitidx = 0;               // 선형 스캔
#endif
  
  size_t m = (mask << bitidx);
  while (bitidx <= bitidx_max) {
    const size_t mapm = (map & m);
    if (mapm == 0) {  // 마스크 비트들이 모두 0인가?
      const size_t newmap = (map | m);
      if (!mi_atomic_cas_strong_acq_rel(field, &map, newmap)) {
        continue;  // CAS 실패 - 다시 시도
      }
      else {
        *bitmap_idx = mi_bitmap_index_create(idx, bitidx);
        return true;  // 성공!
      }
    }
    else {
#ifdef MI_HAVE_FAST_BITSCAN
      const size_t shift = (MI_SIZE_BITS - mi_clz(mapm) - bitidx);
#else
      const size_t shift = 1;
#endif
      bitidx += shift;
      m <<= shift;
    }
  }
  return false;
}
```

### 하드웨어 최적화:
- **비트 스캔**: `ctz`(count trailing zeros) 명령어 활용
- **Compare-and-Swap**: 하드웨어 원자적 연산
- **캐시 라인 정렬**: 64바이트 경계 정렬로 false sharing 방지

---

### 6. 커밋 마스크 최적화 (Virtual Memory Management)

* 세밀한 메모리 제어 (src/segment.c:20-120)

```c
static void mi_commit_mask_create(size_t bitidx, size_t bitcount, mi_commit_mask_t* cm) {
  mi_commit_mask_create_empty(cm);
  size_t i = bitidx / MI_COMMIT_MASK_FIELD_BITS;
  size_t ofs = bitidx % MI_COMMIT_MASK_FIELD_BITS;
  
  while (bitcount > 0) {
    size_t avail = MI_COMMIT_MASK_FIELD_BITS - ofs;
    size_t count = (bitcount > avail ? avail : bitcount);
    size_t mask = (count >= MI_COMMIT_MASK_FIELD_BITS ? 
                   ~((size_t)0) : 
                   (((size_t)1 << count) - 1) << ofs);
    cm->mask[i] = mask;
    bitcount -= count;
    ofs = 0;
    i++;
  }
}

size_t _mi_commit_mask_committed_size(const mi_commit_mask_t* cm, size_t total) {
  size_t count = 0;
  for (size_t i = 0; i < MI_COMMIT_MASK_FIELD_COUNT; i++) {
    size_t mask = cm->mask[i];
    if (~mask == 0) {
      count += MI_COMMIT_MASK_FIELD_BITS;  // 모든 비트 설정됨
    }
    else {
      for (; mask != 0; mask >>= 1) {  // popcount로 최적화 가능
        if ((mask & 1) != 0) count++;
      }
    }
  }
  return ((total / MI_COMMIT_MASK_BITS) * count);
}
```

### 가상 메모리 최적화:
- **64KB 단위 제어**: 운영체제 페이지 크기에 최적화
- **지연 커밋**: 실제 사용될 때까지 물리 메모리 매핑 연기
- **자동 디커밋**: 사용하지 않는 영역 자동 반환

---

## 7. 컴파일러 최적화 활용

* (사전지식) 브랜치 예측이란?
    * CPU는 분기문(if-else)을 만나면 미리 어느 쪽으로 갈지 예측, 
    * 예측이 맞으면 빠르고, 틀리면 파이프라인을 비워야 해서 느려진다

```
// CPU 파이프라인
명령어 1: FETCH → DECODE → EXECUTE → WRITE
명령어 2:         FETCH → DECODE → EXECUTE → WRITE  
명령어 3:                 FETCH → DECODE → EXECUTE → WRITE

// 브랜치 예측 실패 시
if (condition) { ... }
↓ CPU가 true로 예측했는데 실제로는 false
→ 파이프라인 전체를 비우고 다시 시작! (20-30 cycles 손실)
```

```cpp
// ✅ mimalloc 방식
mi_block_t* const block = page->free;
if mi_unlikely(block == NULL) {  // 컴파일러: "이 경우는 거의 일어나지 않는다"
    return _mi_malloc_generic(heap, size, zero, 0);  // 느린 경로
}
// 빠른 경로 계속...

// 컴파일러가 생성하는 어셈블리:
// 1. 빠른 경로를 메인 라인에 배치
// 2. 느린 경로를 멀리 떨어진 곳에 배치
// 3. CPU가 자연스럽게 빠른 경로를 예측하게 됨
```

* 브랜치 예측 힌트:

```c
#if defined(__GNUC__) || defined(__clang__)
#define mi_unlikely(x) (__builtin_expect(!!(x), false))
#define mi_likely(x)   (__builtin_expect(!!(x), true))
#else
#define mi_unlikely(x) (x)
#define mi_likely(x)   (x)
#endif
```

* 인라인 최적화:

```c
// ❌ 함수 호출 방식
void* mi_malloc(size_t size) {
    return _mi_heap_malloc_zero(mi_prim_get_default_heap(), size, false);
}

// 어셈블리로 변환되면:
// 1. 매개변수를 레지스터/스택에 저장    (2-3 cycles)
// 2. 함수 주소로 점프                  (1-2 cycles)  
// 3. 스택 프레임 설정                  (2-3 cycles)
// 4. 실제 작업                        (5-10 cycles)
// 5. 스택 프레임 정리                  (2-3 cycles)
// 6. 원래 위치로 돌아가기               (1-2 cycles)
// 총 13-23 cycles의 오버헤드!
```

```c
#define mi_decl_noinline __attribute__((noinline))  // 큰 함수는 인라인 방지
extern inline                                       // 작은 함수는 강제 인라인
```

```cpp
// ✅ 인라인 할 것들 (작고 자주 호출)
extern inline void* _mi_page_malloc_zero(...) {
    // 단 몇 줄의 핵심 할당 코드
}

// ❌ 인라인 하지 않을 것들 (크고 복잡)
static mi_decl_noinline void mi_page_free_list_extend(...) {
    // 복잡한 페이지 확장 로직 (수십 줄)
}

static mi_decl_noinline void mi_free_block_delayed_mt(...) {
    // 복잡한 멀티스레드 해제 로직
}
```

* 메모리 순서 최적화:

```c
// 원래 코드
data = 42;           // 1. 데이터 설정
ready = true;        // 2. 준비 완료 플래그

// CPU가 최적화한 코드 (순서 바뀜!)
ready = true;        // 2. 준비 완료 플래그 먼저
data = 42;           // 1. 데이터 설정 나중에

// 다른 스레드에서:
if (ready) {         // ready가 true인데
    use(data);       // data는 아직 42가 아님! 🚨
}
```

```c
#define mi_atomic_load_relaxed(p)     atomic_load_explicit(p, memory_order_relaxed)
#define mi_atomic_load_acquire(p)     atomic_load_explicit(p, memory_order_acquire)
#define mi_atomic_store_release(p,x)  atomic_store_explicit(p, x, memory_order_release)
```

